id: B10
name: "AI Provider Interface (Abstract Layer)"
phase: 1
phase_name: "CV Management"

goal: |
  Create an abstract interface for AI providers (OpenAI, Anthropic, Google).
  This allows the app to work with multiple AI services through a unified API.
  This block is moved earlier because AI is needed for CV field extraction.

dependencies: [B01, B02, B03, B04]

files_to_create:
  - id: F066
    path: "src/lib/ai/ai-provider.ts"
    description: "Abstract AI Provider interface"

  - id: F067
    path: "src/lib/ai/openai-provider.ts"
    description: "OpenAI implementation"

  - id: F068
    path: "src/lib/ai/anthropic-provider.ts"
    description: "Anthropic (Claude) implementation"

  - id: F069
    path: "src/lib/ai/google-ai-provider.ts"
    description: "Google AI (Gemini) implementation"

  - id: F070
    path: "src/lib/ai/ai-factory.ts"
    description: "Factory to create AI provider instances"

  - id: F104
    path: "src/lib/ai/index.ts"
    description: "Export all AI modules"

files_to_modify: []

files_available:
  - id: F001
    path: "package.json"
    from_block: B01
  - id: F079
    path: "src/lib/types.ts"
    from_block: B03
  - id: F078
    path: "src/lib/constants.ts"
    from_block: B04

commands: []

instructions: |
  1. Create ai-provider.ts - The abstract interface:
     ```typescript
     // ============================================
     // [F066] src/lib/ai/ai-provider.ts
     // Abstract AI Provider Interface
     // ============================================
     
     import { AIProviderName, AIModel, AIChatMessage } from '@/lib/types';
     
     export interface AIProviderConfig {
       apiKey: string;
       model?: string;
       temperature?: number;
       maxTokens?: number;
     }
     
     export interface AIValidationResult {
       valid: boolean;
       error?: string;
       models?: AIModel[];
       balance?: string | null;
     }
     
     export interface AICompletionOptions {
       model: string;
       messages: AIChatMessage[];
       temperature?: number;
       maxTokens?: number;
       jsonMode?: boolean;  // Request JSON output
     }
     
     export interface AIProvider {
       readonly providerName: AIProviderName;
       
       // Validate API key and get available models
       validateKey(apiKey: string): Promise<AIValidationResult>;
       
       // Get list of available models
       getModels(apiKey: string): Promise<AIModel[]>;
       
       // Simple completion (non-streaming)
       complete(config: AIProviderConfig, options: AICompletionOptions): Promise<string>;
       
       // Streaming completion
       streamComplete(
         config: AIProviderConfig,
         options: AICompletionOptions,
         onChunk: (chunk: string) => void
       ): Promise<string>;
       
       // Parse JSON response (with error handling)
       parseJsonResponse<T>(response: string): T | null;
     }
     
     // Base class with common functionality
     export abstract class BaseAIProvider implements AIProvider {
       abstract readonly providerName: AIProviderName;
       
       abstract validateKey(apiKey: string): Promise<AIValidationResult>;
       abstract getModels(apiKey: string): Promise<AIModel[]>;
       abstract complete(config: AIProviderConfig, options: AICompletionOptions): Promise<string>;
       abstract streamComplete(
         config: AIProviderConfig,
         options: AICompletionOptions,
         onChunk: (chunk: string) => void
       ): Promise<string>;
       
       parseJsonResponse<T>(response: string): T | null {
         try {
           // Try to extract JSON from response
           // Handle cases where AI wraps JSON in markdown code blocks
           let jsonStr = response;
           
           // Remove markdown code blocks if present
           const jsonMatch = response.match(/```(?:json)?\s*([\s\S]*?)\s*```/);
           if (jsonMatch) {
             jsonStr = jsonMatch[1];
           }
           
           return JSON.parse(jsonStr) as T;
         } catch (e) {
           console.error('Failed to parse JSON response:', e);
           return null;
         }
       }
     }
     ```
  
  2. Create openai-provider.ts:
     ```typescript
     // ============================================
     // [F067] src/lib/ai/openai-provider.ts
     // ============================================
     
     import OpenAI from 'openai';
     import { BaseAIProvider, AIProviderConfig, AICompletionOptions, AIValidationResult } from './ai-provider';
     import { AIProviderName, AIModel } from '@/lib/types';
     
     export class OpenAIProvider extends BaseAIProvider {
       readonly providerName: AIProviderName = 'openai';
       
       private createClient(apiKey: string): OpenAI {
         return new OpenAI({ apiKey });
       }
       
       async validateKey(apiKey: string): Promise<AIValidationResult> {
         try {
           const client = this.createClient(apiKey);
           const models = await client.models.list();
           
           const availableModels: AIModel[] = models.data
             .filter(m => m.id.includes('gpt'))
             .map(m => ({
               model_id: m.id,
               model_name: m.id,
               provider: 'openai' as AIProviderName
             }));
           
           return {
             valid: true,
             models: availableModels
           };
         } catch (error: any) {
           return {
             valid: false,
             error: error.message || 'Invalid API key'
           };
         }
       }
       
       async getModels(apiKey: string): Promise<AIModel[]> {
         const result = await this.validateKey(apiKey);
         return result.models || [];
       }
       
       async complete(config: AIProviderConfig, options: AICompletionOptions): Promise<string> {
         const client = this.createClient(config.apiKey);
         
         const response = await client.chat.completions.create({
           model: options.model,
           messages: options.messages.map(m => ({
             role: m.role as 'system' | 'user' | 'assistant',
             content: m.content
           })),
           temperature: options.temperature ?? config.temperature ?? 0.7,
           max_tokens: options.maxTokens ?? config.maxTokens ?? 4096,
           response_format: options.jsonMode ? { type: 'json_object' } : undefined
         });
         
         return response.choices[0]?.message?.content || '';
       }
       
       async streamComplete(
         config: AIProviderConfig,
         options: AICompletionOptions,
         onChunk: (chunk: string) => void
       ): Promise<string> {
         const client = this.createClient(config.apiKey);
         
         const stream = await client.chat.completions.create({
           model: options.model,
           messages: options.messages.map(m => ({
             role: m.role as 'system' | 'user' | 'assistant',
             content: m.content
           })),
           temperature: options.temperature ?? config.temperature ?? 0.7,
           max_tokens: options.maxTokens ?? config.maxTokens ?? 4096,
           stream: true
         });
         
         let fullResponse = '';
         for await (const chunk of stream) {
           const content = chunk.choices[0]?.delta?.content || '';
           fullResponse += content;
           onChunk(content);
         }
         
         return fullResponse;
       }
     }
     ```
  
  3. Create anthropic-provider.ts:
     ```typescript
     // ============================================
     // [F068] src/lib/ai/anthropic-provider.ts
     // ============================================
     
     import Anthropic from '@anthropic-ai/sdk';
     import { BaseAIProvider, AIProviderConfig, AICompletionOptions, AIValidationResult } from './ai-provider';
     import { AIProviderName, AIModel } from '@/lib/types';
     
     export class AnthropicProvider extends BaseAIProvider {
       readonly providerName: AIProviderName = 'anthropic';
       
       // Known Claude models (Anthropic doesn't have a models list API)
       private readonly KNOWN_MODELS: AIModel[] = [
         { model_id: 'claude-3-5-sonnet-20241022', model_name: 'Claude 3.5 Sonnet', provider: 'anthropic' },
         { model_id: 'claude-3-5-haiku-20241022', model_name: 'Claude 3.5 Haiku', provider: 'anthropic' },
         { model_id: 'claude-3-opus-20240229', model_name: 'Claude 3 Opus', provider: 'anthropic' },
         { model_id: 'claude-3-sonnet-20240229', model_name: 'Claude 3 Sonnet', provider: 'anthropic' },
         { model_id: 'claude-3-haiku-20240307', model_name: 'Claude 3 Haiku', provider: 'anthropic' },
       ];
       
       private createClient(apiKey: string): Anthropic {
         return new Anthropic({ apiKey });
       }
       
       async validateKey(apiKey: string): Promise<AIValidationResult> {
         try {
           const client = this.createClient(apiKey);
           
           // Make a minimal API call to verify the key
           await client.messages.create({
             model: 'claude-3-haiku-20240307',
             max_tokens: 10,
             messages: [{ role: 'user', content: 'Hi' }]
           });
           
           return {
             valid: true,
             models: this.KNOWN_MODELS
           };
         } catch (error: any) {
           return {
             valid: false,
             error: error.message || 'Invalid API key'
           };
         }
       }
       
       async getModels(apiKey: string): Promise<AIModel[]> {
         const result = await this.validateKey(apiKey);
         return result.valid ? this.KNOWN_MODELS : [];
       }
       
       async complete(config: AIProviderConfig, options: AICompletionOptions): Promise<string> {
         const client = this.createClient(config.apiKey);
         
         // Extract system message if present
         const systemMsg = options.messages.find(m => m.role === 'system');
         const otherMsgs = options.messages.filter(m => m.role !== 'system');
         
         const response = await client.messages.create({
           model: options.model,
           max_tokens: options.maxTokens ?? config.maxTokens ?? 4096,
           system: systemMsg?.content,
           messages: otherMsgs.map(m => ({
             role: m.role as 'user' | 'assistant',
             content: m.content
           }))
         });
         
         // Extract text from response
         const textBlock = response.content.find(c => c.type === 'text');
         return textBlock?.text || '';
       }
       
       async streamComplete(
         config: AIProviderConfig,
         options: AICompletionOptions,
         onChunk: (chunk: string) => void
       ): Promise<string> {
         const client = this.createClient(config.apiKey);
         
         const systemMsg = options.messages.find(m => m.role === 'system');
         const otherMsgs = options.messages.filter(m => m.role !== 'system');
         
         const stream = await client.messages.stream({
           model: options.model,
           max_tokens: options.maxTokens ?? config.maxTokens ?? 4096,
           system: systemMsg?.content,
           messages: otherMsgs.map(m => ({
             role: m.role as 'user' | 'assistant',
             content: m.content
           }))
         });
         
         let fullResponse = '';
         for await (const event of stream) {
           if (event.type === 'content_block_delta' && event.delta.type === 'text_delta') {
             const text = event.delta.text;
             fullResponse += text;
             onChunk(text);
           }
         }
         
         return fullResponse;
       }
     }
     ```
  
  4. Create google-ai-provider.ts:
     ```typescript
     // ============================================
     // [F069] src/lib/ai/google-ai-provider.ts
     // ============================================
     
     import { GoogleGenerativeAI } from '@google/generative-ai';
     import { BaseAIProvider, AIProviderConfig, AICompletionOptions, AIValidationResult } from './ai-provider';
     import { AIProviderName, AIModel } from '@/lib/types';
     
     export class GoogleAIProvider extends BaseAIProvider {
       readonly providerName: AIProviderName = 'google';
       
       private readonly KNOWN_MODELS: AIModel[] = [
         { model_id: 'gemini-1.5-pro', model_name: 'Gemini 1.5 Pro', provider: 'google' },
         { model_id: 'gemini-1.5-flash', model_name: 'Gemini 1.5 Flash', provider: 'google' },
         { model_id: 'gemini-1.0-pro', model_name: 'Gemini 1.0 Pro', provider: 'google' },
       ];
       
       private createClient(apiKey: string): GoogleGenerativeAI {
         return new GoogleGenerativeAI(apiKey);
       }
       
       async validateKey(apiKey: string): Promise<AIValidationResult> {
         try {
           const client = this.createClient(apiKey);
           const model = client.getGenerativeModel({ model: 'gemini-1.5-flash' });
           
           // Make a minimal API call to verify
           await model.generateContent('Hi');
           
           return {
             valid: true,
             models: this.KNOWN_MODELS
           };
         } catch (error: any) {
           return {
             valid: false,
             error: error.message || 'Invalid API key'
           };
         }
       }
       
       async getModels(apiKey: string): Promise<AIModel[]> {
         const result = await this.validateKey(apiKey);
         return result.valid ? this.KNOWN_MODELS : [];
       }
       
       async complete(config: AIProviderConfig, options: AICompletionOptions): Promise<string> {
         const client = this.createClient(config.apiKey);
         const model = client.getGenerativeModel({ 
           model: options.model,
           generationConfig: {
             temperature: options.temperature ?? config.temperature ?? 0.7,
             maxOutputTokens: options.maxTokens ?? config.maxTokens ?? 4096,
           }
         });
         
         // Convert messages to Gemini format
         const history = options.messages
           .filter(m => m.role !== 'system')
           .slice(0, -1)
           .map(m => ({
             role: m.role === 'assistant' ? 'model' : 'user',
             parts: [{ text: m.content }]
           }));
         
         const systemInstruction = options.messages.find(m => m.role === 'system')?.content;
         const lastMessage = options.messages[options.messages.length - 1];
         
         const chat = model.startChat({
           history,
           systemInstruction
         });
         
         const result = await chat.sendMessage(lastMessage.content);
         return result.response.text();
       }
       
       async streamComplete(
         config: AIProviderConfig,
         options: AICompletionOptions,
         onChunk: (chunk: string) => void
       ): Promise<string> {
         const client = this.createClient(config.apiKey);
         const model = client.getGenerativeModel({ 
           model: options.model,
           generationConfig: {
             temperature: options.temperature ?? config.temperature ?? 0.7,
             maxOutputTokens: options.maxTokens ?? config.maxTokens ?? 4096,
           }
         });
         
         const history = options.messages
           .filter(m => m.role !== 'system')
           .slice(0, -1)
           .map(m => ({
             role: m.role === 'assistant' ? 'model' : 'user',
             parts: [{ text: m.content }]
           }));
         
         const systemInstruction = options.messages.find(m => m.role === 'system')?.content;
         const lastMessage = options.messages[options.messages.length - 1];
         
         const chat = model.startChat({
           history,
           systemInstruction
         });
         
         const result = await chat.sendMessageStream(lastMessage.content);
         
         let fullResponse = '';
         for await (const chunk of result.stream) {
           const text = chunk.text();
           fullResponse += text;
           onChunk(text);
         }
         
         return fullResponse;
       }
     }
     ```
  
  5. Create ai-factory.ts:
     ```typescript
     // ============================================
     // [F070] src/lib/ai/ai-factory.ts
     // ============================================
     
     import { AIProviderName } from '@/lib/types';
     import { AIProvider } from './ai-provider';
     import { OpenAIProvider } from './openai-provider';
     import { AnthropicProvider } from './anthropic-provider';
     import { GoogleAIProvider } from './google-ai-provider';
     
     const providers: Record<AIProviderName, AIProvider> = {
       openai: new OpenAIProvider(),
       anthropic: new AnthropicProvider(),
       google: new GoogleAIProvider(),
     };
     
     export function getAIProvider(name: AIProviderName): AIProvider {
       const provider = providers[name];
       if (!provider) {
         throw new Error(`Unknown AI provider: ${name}`);
       }
       return provider;
     }
     
     export function getAllProviders(): AIProvider[] {
       return Object.values(providers);
     }
     
     export function getProviderNames(): AIProviderName[] {
       return Object.keys(providers) as AIProviderName[];
     }
     ```
  
  6. Create index.ts:
     ```typescript
     // ============================================
     // [F104] src/lib/ai/index.ts
     // ============================================
     
     export * from './ai-provider';
     export * from './openai-provider';
     export * from './anthropic-provider';
     export * from './google-ai-provider';
     export * from './ai-factory';
     ```

checkpoint_tests:
  - id: T01
    description: "All AI provider files exist"
    type: "files_exist"
    files:
      - "src/lib/ai/ai-provider.ts"
      - "src/lib/ai/openai-provider.ts"
      - "src/lib/ai/anthropic-provider.ts"
      - "src/lib/ai/google-ai-provider.ts"
      - "src/lib/ai/ai-factory.ts"
      - "src/lib/ai/index.ts"

  - id: T02
    description: "TypeScript compiles without errors"
    type: "command"
    command: "npx tsc --noEmit"
    expected_exit_code: 0

  - id: T03
    description: "ai-provider.ts exports interface and base class"
    type: "grep"
    file: "src/lib/ai/ai-provider.ts"
    patterns:
      - "export interface AIProvider"
      - "export abstract class BaseAIProvider"
      - "validateKey"
      - "complete"
      - "streamComplete"
      - "parseJsonResponse"

  - id: T04
    description: "All providers extend BaseAIProvider"
    type: "grep"
    file: "src/lib/ai/openai-provider.ts"
    patterns:
      - "extends BaseAIProvider"
      - "OpenAI"

  - id: T05
    description: "Factory exports getAIProvider"
    type: "grep"
    file: "src/lib/ai/ai-factory.ts"
    patterns:
      - "export function getAIProvider"
      - "openai"
      - "anthropic"
      - "google"

  - id: T06
    description: "index.ts exports all modules"
    type: "grep"
    file: "src/lib/ai/index.ts"
    patterns:
      - "ai-provider"
      - "ai-factory"
      - "openai-provider"
      - "anthropic-provider"
      - "google-ai-provider"

max_retries: 3